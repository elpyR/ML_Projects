{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Author: Lou Pemberton (Intern)\n",
        "# Date: August 2022\n",
        "# Description: This notebook takes a file as input, creates a Pandas DataFrame, then uses the SRL-BERT model from allennlp to annotate the sentences in a specific column.\n",
        "# The SRL annotations are then extracted (verbs, arg0, and arg1 annotations, plus the sentence Id and text) \n",
        "# These extracted SRL annotations are then encoded using BERT before saving to a CSV file to use in embeddings_projector.ipynb.\n",
        "# THIS NOTEBOOK CAN BE USED INSTEAD OF SRL_Vectors.ipynb IF YOU NEED SENTENCES SRL ANNOTATED PRIOR TO EXTRACTING AND ENCODING. IF YOU ALREADY HAVE SRL ANNOTATED DATA, USE SRL_Vectors.ipynb BEFORE embeddings_projector.ipynb"
      ],
      "metadata": {
        "id": "0-HjEDcWdymn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acxlQ34ET-Ph"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPIimME1USj7",
        "outputId": "eae065e4-a17c-479c-f246-9cf6fb8fc73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Pandas DataFrame from file\n",
        "filepath = # enter filepath in GDrive\n",
        "df = pd.read_csv(filepath) "
      ],
      "metadata": {
        "id": "77TAaQeYUcl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(40)"
      ],
      "metadata": {
        "id": "zG8bsdeAcWJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some data wrangling and preprocessing"
      ],
      "metadata": {
        "id": "M-sqpT9_aHBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Id'] = range(1, len(df) + 1) # adds an Id column if none currently in df"
      ],
      "metadata": {
        "id": "zwaYe9tpdVxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = df.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df = df[cols]"
      ],
      "metadata": {
        "id": "PfSUlBwpduBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['publishMonth', 'Matched Interesting Commercial Actions', 'topics_ICA_title_num_match','cluster'], axis=1) # amend as needed"
      ],
      "metadata": {
        "id": "dOCJsXdDUqs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start of SRL annotations\n",
        "# installs SRL-BERT model from allennlp and spacy-transformers\n",
        "\n",
        "#! pip install allennlp==2.1.0 allennlp-models==2.1.0 #uncomment if required\n",
        "#! pip install git+https://github.com/explosion/spacy-transformers #uncomment if required"
      ],
      "metadata": {
        "id": "sgYQQ0tPViej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import predictor from allennlp\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.tagging"
      ],
      "metadata": {
        "id": "f6SzWe9_Vnk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename column to fit model\n",
        "df.rename(columns = {'Cluster Representative':'SentenceText'}, inplace = True)"
      ],
      "metadata": {
        "id": "U_dAAORtXDHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put SentenceText column to list\n",
        "cf_list = df.SentenceText.tolist()"
      ],
      "metadata": {
        "id": "NPzHiKkwW25z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run SRL_BERT model to get SRL annotations and appends to list SemanticRoleLabels\n",
        "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n",
        "\n",
        "SemanticRoleLabels = []\n",
        "\n",
        "for sentence in cf_list:\n",
        "  srl = predictor.predict(sentence)\n",
        "  SemanticRoleLabels.append(srl)"
      ],
      "metadata": {
        "id": "dhNEjOtLVhwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AMEND BELOW AS NEEDED - Notice spellings of 'MLPreProcessedSentences' and 'MLPreprocessedSentences' #"
      ],
      "metadata": {
        "id": "fhnFvRwL_t_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SemanticRoleLabels'] = SemanticRoleLabels #creates a column for SRL"
      ],
      "metadata": {
        "id": "k6hTeJwir2gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLPreProcessedSentences = df.apply(lambda x: (x.to_dict()), axis=1) #puts MLPreprocessedSentences from SemanticRoleLabels list to dictionary"
      ],
      "metadata": {
        "id": "UrRWiyVA1mvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MLPreProcessedSentences'] = MLPreProcessedSentences #puts MLPreProcessedSentences dictionary to column in DataFrame"
      ],
      "metadata": {
        "id": "w25n7T2l1pUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLPreprocessedSentences =  df['MLPreProcessedSentences'] = [[i] for i in df['MLPreProcessedSentences']] #iterates through each row in MLPreProcessedSentences and creates a list MLPreprocessedSentences (notice different spelling)"
      ],
      "metadata": {
        "id": "DPdJILst6xov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracts the SRL annotations and SentenceText and Id (for sentence) and creates a list final_dataset which includes each row\n",
        "final_dataset = []\n",
        "\n",
        "for idx in range(len(MLPreprocessedSentences)):\n",
        "    doc = MLPreprocessedSentences[idx]\n",
        "    for sent_dict in doc:\n",
        "        sent_text = sent_dict['SentenceText']\n",
        "        sent_id = sent_dict['Id']\n",
        "        srl = sent_dict['SemanticRoleLabels']\n",
        "        srl_verb_list = srl['verbs']\n",
        "        if srl_verb_list:\n",
        "            for srl_annotations in srl_verb_list:\n",
        "                verb_annotation = srl_annotations['verb']\n",
        "                description_annotation = srl_annotations['description']\n",
        "                arg0_des = re.findall('\\[[ARG0]+?:(.*?)\\]', description_annotation)\n",
        "                arg1_des = re.findall('\\[[ARG1]+?:(.*?)\\]', description_annotation)\n",
        "                if arg0_des and arg1_des:\n",
        "                    row = {\n",
        "                        'sent_id':sent_id,\n",
        "                        'sentence':sent_text,\n",
        "                        'verb':verb_annotation,\n",
        "                        'arg0_des':arg0_des[0],\n",
        "                        'arg1_des':arg1_des[0]\n",
        "                    }\n",
        "                    final_dataset.append(row)"
      ],
      "metadata": {
        "id": "ul27nR-D608f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# puts final_dataset list to Pandas DataFrame\n",
        "finaldf = pd.DataFrame(final_dataset)"
      ],
      "metadata": {
        "id": "Tuh8tz9F610r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#limits the length of arguments for arg0 and arg1\n",
        "finaldf = finaldf[ \n",
        "        (finaldf.arg0_des.apply(lambda x:len(x.split()) <= 3)) \n",
        "        & \n",
        "        (finaldf.arg1_des.apply(lambda x:len(x.split()) <= 3)) \n",
        "       ]"
      ],
      "metadata": {
        "id": "HMGDHhkp7NN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldf.head()"
      ],
      "metadata": {
        "id": "HecfrZjT66f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#puts each annotation column into a list\n",
        "verb_list = list(finaldf.verb)\n",
        "arg0_list = list(finaldf.arg0_des)\n",
        "arg1_list = list(finaldf.arg1_des)"
      ],
      "metadata": {
        "id": "pjbXbA1E7Sob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start of BERT embeddings\n",
        "#!pip install -U sentence-transformers #uncomment if required to install"
      ],
      "metadata": {
        "id": "13h5rAnw7bil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports library and creates BERT model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "bert = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "OCWEM1i77V53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get BERT verb embeddings\n",
        "batch_size = 64\n",
        "verb_embeddings = []\n",
        "for i in range(0, len(verb_list), batch_size):\n",
        "    verb_embeddings.extend(bert.encode(verb_list[i:i+batch_size], batch_size=batch_size))\n",
        "    print(f\"Batch {i} encoding finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXpiDHmC7cez",
        "outputId": "e8f6fbc9-efe8-4af6-d2bd-f531b3ce04b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 encoding finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get BERT arg0 embeddings\n",
        "batch_size = 64\n",
        "agent_embeddings = []\n",
        "for i in range(0, len(arg0_list), batch_size):\n",
        "    agent_embeddings.extend(bert.encode(arg0_list[i:i+batch_size], batch_size=batch_size))\n",
        "    print(f\"Batch {i} encoding finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF56_1Ws7gZp",
        "outputId": "beedf554-30e4-4254-c8c9-f0559aa07e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 encoding finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get BERT arg1 embeddings\n",
        "batch_size = 64\n",
        "theme_embeddings = []\n",
        "for i in range(0, len(arg1_list), batch_size):\n",
        "    theme_embeddings.extend(bert.encode(arg1_list[i:i+batch_size], batch_size=batch_size))\n",
        "    print(f\"Batch {i} encoding finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkh9Jqpb7kx5",
        "outputId": "d9162a7c-ca63-4cc6-8be3-d6b2e4a2984c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 encoding finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add embeddings for annotations to DataFrame\n",
        "finaldf['verb_embeddings'] = verb_embeddings\n",
        "finaldf['arg0_embeddings'] = agent_embeddings\n",
        "finaldf['arg1_embeddings'] = theme_embeddings"
      ],
      "metadata": {
        "id": "QF-fqaAT7paj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldf.head()"
      ],
      "metadata": {
        "id": "xGenz06L7r_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save SRL annotations and BERT embeddings to csv #\n",
        "\n",
        "#finaldf.to_csv(FILE LOCATION GOES HERE)"
      ],
      "metadata": {
        "id": "COutRT_n7u6J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}